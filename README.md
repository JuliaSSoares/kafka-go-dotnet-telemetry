# ğŸ“¡ Real-time Telemetry Pipeline (Go + Kafka + .NET)
![Status](https://img.shields.io/badge/status-under--construction-orange)

Sistema distribuÃ­do de alta performance para ingestÃ£o, processamento e monitoramento de telemetria GPS em tempo real.

Este projeto implementa uma **Arquitetura Orientada a Eventos (EDA)** com foco em **resiliÃªncia**, **consistÃªncia** e **baixa latÃªncia**.

---

## ğŸ“‹ Ãndice

- [ğŸ—ï¸ Arquitetura do Sistema](#ï¸-arquitetura-do-sistema)
- [ğŸ“ Diagramas TÃ©cnicos](#-diagramas-tÃ©cnicos)
  - [Diagrama C4 - NÃ­vel 1: Contexto](#diagrama-c4---nÃ­vel-1-contexto-do-sistema)
  - [Diagrama C4 - NÃ­vel 2: Container](#diagrama-c4---nÃ­vel-2-container)
  - [Diagrama C4 - NÃ­vel 3: Producer](#diagrama-c4---nÃ­vel-3-componente-producer)
  - [Diagrama C4 - NÃ­vel 3: Consumer](#diagrama-c4---nÃ­vel-3-componente-consumer)
  - [Diagrama de SequÃªncia](#diagrama-de-sequÃªncia-fluxo-completo)
  - [Diagrama de Deployment](#diagrama-de-deployment)
- [ğŸ“‹ ADRs - Architectural Decision Records](#-adrs---architectural-decision-records)
- [ğŸ› ï¸ Stack TecnolÃ³gico](#ï¸-stack-tecnolÃ³gico)
- [ğŸš€ Diferenciais TÃ©cnicos](#-diferenciais-tÃ©cnicos)
- [âš¡ Como Executar](#-como-executar)
- [ğŸ§¹ Comandos Ãšteis](#-comandos-Ãºteis)

---

## ğŸ—ï¸ Arquitetura do Sistema

O sistema simula um cenÃ¡rio logÃ­stico real, onde frotas de entregadores enviam coordenadas GPS continuamente. A arquitetura foi desenhada para garantir que **nenhum dado seja perdido** (via **Outbox Pattern**) e que a leitura seja **instantÃ¢nea** (via **Redis**).

---

## ğŸ“ Diagramas TÃ©cnicos

### Diagrama C4 - NÃ­vel 1: Contexto do Sistema

```mermaid
%%{init: {'theme':'dark', 'themeVariables': { 'primaryColor':'#00ADD8','primaryTextColor':'#fff','primaryBorderColor':'#00758F','lineColor':'#60A5FA','secondaryColor':'#512BD4','tertiaryColor':'#DC382D'}}}%%
graph TB
    subgraph External["ğŸŒ Atores Externos"]
        Driver["ğŸ‘¤ Entregador<br/><small>Motorista com GPS</small>"]
        Dispatch["ğŸ“¦ Sistema de Despacho<br/><small>Coordena rotas</small>"]
        Dashboard["ğŸ“Š Dashboard Analytics<br/><small>BI e RelatÃ³rios</small>"]
    end
    
    subgraph Core["âš¡ Sistema Core"]
        Telemetry["ğŸ¯ Sistema de Telemetria<br/><small>Pipeline GPS Real-time</small>"]
    end
    
    Driver -->|"ğŸ“ Envia posiÃ§Ãµes GPS<br/>HTTPS/GPS"| Telemetry
    Telemetry -->|"ğŸ”” Notifica eventos<br/>WebSocket"| Dispatch
    Telemetry -->|"ğŸ“ˆ Fornece dados<br/>REST API"| Dashboard
    
    style Driver fill:#3B82F6,stroke:#1E40AF,stroke-width:2px,color:#fff
    style Dispatch fill:#8B5CF6,stroke:#6D28D9,stroke-width:2px,color:#fff
    style Dashboard fill:#EC4899,stroke:#BE185D,stroke-width:2px,color:#fff
    style Telemetry fill:#10B981,stroke:#059669,stroke-width:3px,color:#fff
    style External fill:#1E293B,stroke:#475569,stroke-width:2px
    style Core fill:#0F172A,stroke:#475569,stroke-width:3px
```

### Diagrama C4 - NÃ­vel 2: Container

```mermaid
%%{init: {'theme':'dark'}}%%
graph TB
    subgraph Producers["ğŸ”µ Producer Layer (Go)"]
        Simulator["ğŸ“¡ GPS Simulator<br/>â”â”â”â”â”â”â”â”â”â”<br/>ğŸ”· Go 1.21<br/><small>Simula sensores GPS</small>"]
        Relay["ğŸ”„ Outbox Relay<br/>â”â”â”â”â”â”â”â”â”â”<br/>ğŸ”· Go 1.21<br/><small>Processa outbox</small>"]
    end
    
    subgraph Broker["ğŸŸ£ Message Broker"]
        Kafka["âš¡ Apache Kafka<br/>â”â”â”â”â”â”â”â”â”â”<br/>ğŸŸ£ Kafka 7.5.0<br/><small>Event Streaming</small>"]
    end
    
    subgraph Consumers["ğŸŸ¢ Consumer Layer (.NET)"]
        Worker["âš™ï¸ Event Processor<br/>â”â”â”â”â”â”â”â”â”â”<br/>ğŸŸ¢ .NET 10<br/><small>Processa eventos</small>"]
    end
    
    subgraph Storage["ğŸ’¾ Storage Layer"]
        Postgres[("ğŸ˜ PostgreSQL<br/>â”â”â”â”â”â”â”â”â”â”<br/>Outbox + HistÃ³rico")]
        Redis[("âš¡ Redis<br/>â”â”â”â”â”â”â”â”â”â”<br/>Estado Atual")]
    end
    
    Simulator -->|"ğŸ’¾ INSERT<br/>status=PENDING"| Postgres
    Relay -->|"ğŸ” SELECT<br/>WHERE status=PENDING"| Postgres
    Relay -->|"ğŸ“¤ Produce<br/>telemetry.positions"| Kafka
    Kafka -->|"ğŸ“¥ Consume<br/>Consumer Group"| Worker
    Worker -->|"ğŸ’¾ INSERT<br/>positions table"| Postgres
    Worker -->|"âš¡ SET with TTL<br/>telemetry:driver_id"| Redis
    
    style Simulator fill:#00ADD8,stroke:#00758F,stroke-width:3px,color:#fff
    style Relay fill:#00ADD8,stroke:#00758F,stroke-width:3px,color:#fff
    style Kafka fill:#231F20,stroke:#000,stroke-width:3px,color:#fff
    style Worker fill:#512BD4,stroke:#3730A3,stroke-width:3px,color:#fff
    style Postgres fill:#336791,stroke:#1E3A5F,stroke-width:3px,color:#fff
    style Redis fill:#DC382D,stroke:#991B1B,stroke-width:3px,color:#fff
    style Producers fill:#0C4A6E,stroke:#075985,stroke-width:2px
    style Broker fill:#4C1D95,stroke:#5B21B6,stroke-width:2px
    style Consumers fill:#166534,stroke:#15803D,stroke-width:2px
    style Storage fill:#7C2D12,stroke:#9A3412,stroke-width:2px
```

### Diagrama C4 - NÃ­vel 3: Componente (Producer)

```mermaid
%%{init: {'theme':'dark'}}%%
graph TB
    subgraph Simulator["ğŸ“¡ GPS Simulator (Go)"]
        Generator["ğŸ² Sensor Generator<br/>â”â”â”â”â”â”â”â”â”â”<br/>âš¡ Go Routine<br/><small>Gera coordenadas GPS</small>"]
        Validator1["âœ… Data Validator<br/>â”â”â”â”â”â”â”â”â”â”<br/>ğŸ“‹ Go<br/><small>Valida lat/lon</small>"]
        OutboxWriter["ğŸ’¾ Outbox Writer<br/>â”â”â”â”â”â”â”â”â”â”<br/>ğŸ”· pgx driver<br/><small>TransaÃ§Ã£o ACID</small>"]
    end
    
    subgraph Relay["ğŸ”„ Outbox Relay (Go)"]
        Poller["ğŸ” Outbox Poller<br/>â”â”â”â”â”â”â”â”â”â”<br/>âš¡ Go Routine<br/><small>Monitora PENDING</small>"]
        Publisher["ğŸ“¤ Kafka Publisher<br/>â”â”â”â”â”â”â”â”â”â”<br/>ğŸŸ£ confluent-kafka-go<br/><small>Publica eventos</small>"]
    end
    
    subgraph Database["ğŸ’¾ PostgreSQL"]
        OutboxTable[("ğŸ“‹ Outbox Table<br/>â”â”â”â”â”â”â”â”â”â”<br/>id, payload, status<br/>created_at, processed_at")]
    end
    
    Generator -->|"ğŸ“Š Payload GPS"| Validator1
    Validator1 -->|"âœ… Dados vÃ¡lidos"| OutboxWriter
    OutboxWriter -->|"ğŸ’¾ INSERT<br/>status='PENDING'"| OutboxTable
    Poller -->|"ğŸ” SELECT * FROM outbox<br/>WHERE status='PENDING'"| OutboxTable
    Poller -->|"ğŸ“¤ Eventos"| Publisher
    Publisher -->|"âœ… UPDATE<br/>status='PROCESSED'"| OutboxTable
    
    style Generator fill:#06B6D4,stroke:#0891B2,stroke-width:2px,color:#fff
    style Validator1 fill:#10B981,stroke:#059669,stroke-width:2px,color:#fff
    style OutboxWriter fill:#8B5CF6,stroke:#7C3AED,stroke-width:2px,color:#fff
    style Poller fill:#F59E0B,stroke:#D97706,stroke-width:2px,color:#fff
    style Publisher fill:#EF4444,stroke:#DC2626,stroke-width:2px,color:#fff
    style OutboxTable fill:#336791,stroke:#1E3A5F,stroke-width:3px,color:#fff
    style Simulator fill:#0C4A6E,stroke:#075985,stroke-width:2px
    style Relay fill:#064E3B,stroke:#047857,stroke-width:2px
    style Database fill:#1E293B,stroke:#334155,stroke-width:2px
```

### Diagrama C4 - NÃ­vel 3: Componente (Consumer)

```mermaid
%%{init: {'theme':'dark'}}%%
graph TB
    subgraph KafkaLayer["ğŸŸ£ Kafka Layer"]
        Consumer["ğŸ“¥ Kafka Consumer<br/>â”â”â”â”â”â”â”â”â”â”<br/>ğŸŸ£ Confluent.Kafka<br/><small>Subscribe + Poll</small>"]
    end
    
    subgraph ProcessingLayer["âš™ï¸ Processing Layer (.NET)"]
        Validator2["âœ… Message Validator<br/>â”â”â”â”â”â”â”â”â”â”<br/>ğŸ“‹ FluentValidation<br/><small>Schema validation</small>"]
        Handler["ğŸ¯ Event Handler<br/>â”â”â”â”â”â”â”â”â”â”<br/>ğŸ’ MediatR<br/><small>CQRS Pattern</small>"]
    end
    
    subgraph PersistenceLayer["ğŸ’¾ Persistence Layer"]
        Repository["ğŸ’¾ Position Repository<br/>â”â”â”â”â”â”â”â”â”â”<br/>ğŸŸ¢ Entity Framework Core<br/><small>ORM + Migrations</small>"]
        CacheManager["âš¡ Cache Manager<br/>â”â”â”â”â”â”â”â”â”â”<br/>ğŸ”´ StackExchange.Redis<br/><small>Key-Value Store</small>"]
    end
    
    subgraph StorageLayer["ğŸ’¾ Storage"]
        PG[("ğŸ˜ PostgreSQL<br/>â”â”â”â”â”â”â”â”â”â”<br/>positions table")]
        RD[("âš¡ Redis<br/>â”â”â”â”â”â”â”â”â”â”<br/>telemetry:* keys")]
    end
    
    Consumer -->|"ğŸ“¨ Message"| Validator2
    Validator2 -->|"âœ… Valid DTO"| Handler
    Handler -->|"ğŸ’¾ Save"| Repository
    Handler -->|"âš¡ Update"| CacheManager
    Repository -->|"INSERT INTO positions"| PG
    CacheManager -->|"SET key value EX 3600"| RD
    
    style Consumer fill:#231F20,stroke:#000,stroke-width:3px,color:#fff
    style Validator2 fill:#10B981,stroke:#059669,stroke-width:2px,color:#fff
    style Handler fill:#8B5CF6,stroke:#7C3AED,stroke-width:2px,color:#fff
    style Repository fill:#3B82F6,stroke:#2563EB,stroke-width:2px,color:#fff
    style CacheManager fill:#EF4444,stroke:#DC2626,stroke-width:2px,color:#fff
    style PG fill:#336791,stroke:#1E3A5F,stroke-width:3px,color:#fff
    style RD fill:#DC382D,stroke:#991B1B,stroke-width:3px,color:#fff
    style KafkaLayer fill:#1E1B4B,stroke:#312E81,stroke-width:2px
    style ProcessingLayer fill:#1E3A8A,stroke:#1E40AF,stroke-width:2px
    style PersistenceLayer fill:#064E3B,stroke:#047857,stroke-width:2px
    style StorageLayer fill:#1E293B,stroke:#334155,stroke-width:2px
```

### Diagrama de SequÃªncia: Fluxo Completo

```mermaid
%%{init: {'theme':'dark', 'sequence': {'actorMargin':50, 'boxMargin':10}}}%%
sequenceDiagram
    autonumber
    participant S as ğŸ“¡ GPS Simulator
    participant DB as ğŸ˜ PostgreSQL
    participant R as ğŸ”„ Relay Service
    participant K as âš¡ Kafka
    participant W as âš™ï¸ Worker .NET
    participant RD as ğŸ”´ Redis

    rect rgb(25, 50, 75)
        Note over S,DB: ğŸ’¾ Fase 1: IngestÃ£o Transacional
        S->>DB: BEGIN TRANSACTION
        S->>DB: INSERT INTO outbox<br/>(payload, status='PENDING')
        DB-->>S: âœ… Row inserted
        S->>DB: COMMIT TRANSACTION
        Note over DB: ğŸ“‹ Dados seguros no outbox
    end

    rect rgb(50, 25, 75)
        Note over R,K: ğŸ“¤ Fase 2: Relay & Publish
        loop Polling cada 1s
            R->>DB: ğŸ” SELECT * FROM outbox<br/>WHERE status='PENDING'<br/>LIMIT 100
            DB-->>R: ğŸ“Š Registros pendentes
            
            R->>K: ğŸ“¤ Produce(topic: telemetry.positions,<br/>key: driver_id, value: json)
            K-->>R: âœ… ACK (offset: 12345)
            
            R->>DB: âœ… UPDATE outbox<br/>SET status='PROCESSED',<br/>processed_at=NOW()
        end
    end

    rect rgb(25, 75, 50)
        Note over K,RD: ğŸ¯ Fase 3: Consumo & Processamento
        K->>W: ğŸ“¥ Message delivered<br/>(partition: 0, offset: 12345)
        W->>W: âœ… Deserialize JSON<br/>& Validate schema
        
        par PersistÃªncia Paralela
            W->>DB: ğŸ’¾ INSERT INTO positions<br/>(driver_id, lat, lon,<br/>timestamp, created_at)
            DB-->>W: âœ… Saved
        and
            W->>RD: âš¡ SET telemetry:driver_123<br/>value: {lat, lon, ts}<br/>EX 3600
            RD-->>W: âœ… Cached
        end
        
        W->>K: âœ… Commit offset 12345
        Note over W: ğŸ‰ Evento processado com sucesso
    end

    rect rgb(75, 50, 25)
        Note over RD: ğŸ” Estado Final
        Note over DB: ğŸ“š HistÃ³rico completo armazenado
        Note over RD: âš¡ Ãšltima posiÃ§Ã£o em cache (TTL: 1h)
    end
```

### Diagrama de Deployment

```mermaid
%%{init: {'theme':'dark'}}%%
graph TB
    subgraph DockerCompose["ğŸ³ Docker Compose Environment"]
        subgraph DataLayer["ğŸ’¾ Data Layer"]
            PG["ğŸ˜ PostgreSQL<br/>â”â”â”â”â”â”â”â”â”â”<br/>ğŸ“¦ postgres:15-alpine<br/>ğŸ”Œ Port: 5432<br/>ğŸ’¾ Volume: postgres_data"]
            RD["âš¡ Redis<br/>â”â”â”â”â”â”â”â”â”â”<br/>ğŸ“¦ redis:7-alpine<br/>ğŸ”Œ Port: 6379<br/>ğŸ’¾ Volume: redis_data"]
        end
        
        subgraph MessageBroker["ğŸŸ£ Message Broker"]
            ZK["ğŸ”· Zookeeper<br/>â”â”â”â”â”â”â”â”â”â”<br/>ğŸ“¦ confluentinc/cp-zookeeper:7.5.0<br/>ğŸ”Œ Port: 2181"]
            KF["âš¡ Apache Kafka<br/>â”â”â”â”â”â”â”â”â”â”<br/>ğŸ“¦ confluentinc/cp-kafka:7.5.0<br/>ğŸ”Œ Ports: 9092, 29092<br/>âš™ï¸ Replication: 1"]
        end
        
        subgraph ApplicationLayer["ğŸ¯ Application Layer"]
            PROD["ğŸ”µ Producer Go<br/>â”â”â”â”â”â”â”â”â”â”<br/>ğŸ“¦ golang:1.21-bullseye<br/>âš™ï¸ Simulator + Relay<br/>ğŸ”— Connects: PostgreSQL, Kafka"]
            CONS["ğŸŸ¢ Consumer .NET<br/>â”â”â”â”â”â”â”â”â”â”<br/>ğŸ“¦ mcr.microsoft.com/dotnet/runtime:10.0<br/>âš™ï¸ Worker Service<br/>ğŸ”— Connects: Kafka, PostgreSQL, Redis"]
        end
        
        subgraph Observability["ğŸ“Š Observability"]
            RI["ğŸ“ˆ RedisInsight<br/>â”â”â”â”â”â”â”â”â”â”<br/>ğŸ“¦ redislabs/redisinsight:latest<br/>ğŸ”Œ Port: 8001<br/>ğŸŒ UI: http://localhost:8001"]
        end
    end
    
    PROD -->|"ğŸ’¾ Write Outbox<br/>SQL INSERT"| PG
    PROD -->|"ğŸ“¤ Produce Events<br/>TCP:29092"| KF
    KF -->|"ğŸ“¥ Consume Events<br/>Consumer Group"| CONS
    CONS -->|"ğŸ’¾ Write History<br/>SQL INSERT"| PG
    CONS -->|"âš¡ Update State<br/>Redis Protocol"| RD
    RI -.->|"ğŸ“Š Monitor Real-time<br/>HTTP"| RD
    ZK -.->|"ğŸ”§ Cluster Management<br/>Coordination"| KF
    
    style PG fill:#336791,stroke:#1E3A5F,stroke-width:3px,color:#fff
    style RD fill:#DC382D,stroke:#991B1B,stroke-width:3px,color:#fff
    style ZK fill:#4A5568,stroke:#2D3748,stroke-width:2px,color:#fff
    style KF fill:#231F20,stroke:#000,stroke-width:3px,color:#fff
    style PROD fill:#00ADD8,stroke:#00758F,stroke-width:3px,color:#fff
    style CONS fill:#512BD4,stroke:#3730A3,stroke-width:3px,color:#fff
    style RI fill:#EF4444,stroke:#DC2626,stroke-width:2px,color:#fff
    style DockerCompose fill:#0F172A,stroke:#1E293B,stroke-width:3px
    style DataLayer fill:#1E293B,stroke:#334155,stroke-width:2px
    style MessageBroker fill:#312E81,stroke:#4C1D95,stroke-width:2px
    style ApplicationLayer fill:#064E3B,stroke:#065F46,stroke-width:2px
    style Observability fill:#7C2D12,stroke:#92400E,stroke-width:2px
```

---

## ğŸ“‹ ADRs - Architectural Decision Records

### ADR-001: Uso do Transactional Outbox Pattern

**Status:** âœ… Aprovado  
**Data:** 2026-01-20  
**Contexto:** Necessidade de garantir entrega de eventos sem perda de dados em caso de falha do Kafka.

**DecisÃ£o:** Implementar Outbox Pattern com PostgreSQL como buffer transacional.

**ConsequÃªncias:**
- âœ… **Positivas:**
  - Atomicidade garantida entre escrita no banco e publicaÃ§Ã£o no Kafka
  - ResiliÃªncia a falhas temporÃ¡rias do Kafka
  - Possibilidade de retry automÃ¡tico
  - Auditoria completa de eventos

- âŒ **Negativas:**
  - LatÃªncia adicional (polling interval ~1s)
  - Necessidade de processo separado (Relay)
  - Maior uso de disco no PostgreSQL

**Alternativas Consideradas:**
1. **PublicaÃ§Ã£o direta no Kafka** - Descartado por falta de atomicidade
2. **CDC (Change Data Capture)** - Complexidade operacional elevada
3. **Dual Write** - Risco de inconsistÃªncia

---

### ADR-002: Escolha de Go para o Producer

**Status:** âœ… Aprovado  
**Data:** 2026-01-20  
**Contexto:** Necessidade de alta concorrÃªncia para simular milhares de sensores GPS simultÃ¢neos.

**DecisÃ£o:** Utilizar Go (Golang) para o Producer (Simulator + Relay).

**ConsequÃªncias:**
- âœ… **Positivas:**
  - Goroutines para concorrÃªncia leve (10.000+ sensores simultÃ¢neos)
  - Performance nativa sem overhead de runtime
  - Baixo consumo de memÃ³ria (~25MB por instÃ¢ncia)
  - Excelente suporte a I/O nÃ£o-bloqueante
  - CompilaÃ§Ã£o estÃ¡tica (binÃ¡rio Ãºnico)

- âŒ **Negativas:**
  - Curva de aprendizado para desenvolvedores sem experiÃªncia em Go
  - Ecossistema menor comparado a Java/C#
  - Menos ferramentas de debugging visual

**Alternativas Consideradas:**
1. **Java com Virtual Threads** - Mais verboso, maior consumo de memÃ³ria
2. **Node.js** - Single-threaded, menor throughput
3. **Rust** - Curva de aprendizado muito Ã­ngreme

---

### ADR-003: Escolha de .NET para o Consumer

**Status:** âœ… Aprovado  
**Data:** 2026-01-20  
**Contexto:** Necessidade de processamento robusto com suporte a ORM e padrÃµes empresariais.

**DecisÃ£o:** Utilizar .NET 10 com Worker Service para o Consumer.

**ConsequÃªncias:**
- âœ… **Positivas:**
  - Entity Framework Core para persistÃªncia robusta
  - MediatR para CQRS e desacoplamento
  - Suporte nativo a DI (Dependency Injection)
  - Ecossistema maduro para aplicaÃ§Ãµes empresariais
  - Performance excelente (.NET 10 com AOT)
  - Strong typing e nullability check

- âŒ **Negativas:**
  - Maior uso de memÃ³ria comparado a Go (~150MB)
  - Runtime maior (Docker image ~200MB)
  - Startup time ligeiramente maior

**Alternativas Consideradas:**
1. **Go tambÃ©m no Consumer** - Menos produtividade, sem ORM robusto
2. **Java com Spring** - Mais pesado e verboso
3. **Python** - Performance inferior, GIL limitations

---

### ADR-004: Redis como Fast Layer

**Status:** âœ… Aprovado  
**Data:** 2026-01-20  
**Contexto:** Necessidade de acesso O(1) Ã  Ãºltima posiÃ§Ã£o conhecida de cada motorista.

**DecisÃ£o:** Utilizar Redis como camada de cache para estado atual.

**ConsequÃªncias:**
- âœ… **Positivas:**
  - LatÃªncia sub-milissegundo (< 1ms p99)
  - Estruturas de dados ricas (Hashes, Sets, Sorted Sets)
  - TTL automÃ¡tico para expiraÃ§Ã£o (evita memory leaks)
  - Pub/Sub para eventos em tempo real
  - Suporte a Lua scripts para operaÃ§Ãµes atÃ´micas
  - ReplicaÃ§Ã£o master-slave disponÃ­vel

- âŒ **Negativas:**
  - Dados volÃ¡teis (nÃ£o Ã© source of truth)
  - Necessidade de warm-up apÃ³s restart
  - Custo de memÃ³ria RAM (~1KB por chave)
  - Sem suporte a queries complexas

**Alternativas Consideradas:**
1. **PostgreSQL com Ã­ndices** - LatÃªncia > 10ms, nÃ£o escalÃ¡vel
2. **Memcached** - Menos features, sem TTL por chave
3. **In-Memory do prÃ³prio .NET** - NÃ£o compartilhado entre instÃ¢ncias

---

### ADR-005: Kafka como Message Broker

**Status:** âœ… Aprovado  
**Data:** 2026-01-20  
**Contexto:** Necessidade de streaming de eventos com alta vazÃ£o e durabilidade.

**DecisÃ£o:** Utilizar Apache Kafka como broker de mensagens.

**ConsequÃªncias:**
- âœ… **Positivas:**
  - Throughput de 100k+ msg/s por partition
  - RetenÃ§Ã£o configurÃ¡vel (replay de eventos)
  - Particionamento para escalabilidade horizontal
  - Consumer Groups para load balancing
  - Garantia de ordem dentro de partiÃ§Ãµes
  - Exatamente uma vez (exactly-once semantics) disponÃ­vel
  - Ecosystem rico (Connect, Streams, KSQL)

- âŒ **Negativas:**
  - Complexidade operacional (Zookeeper atÃ© versÃ£o 3.x)
  - Overhead de infraestrutura (mÃ­nimo 3 brokers em produÃ§Ã£o)
  - Curva de aprendizado significativa
  - NÃ£o Ã© adequado para mensagens com prioridades

**Alternativas Consideradas:**
1. **RabbitMQ** - Menor throughput, melhor para RPC patterns
2. **AWS SQS/SNS** - Vendor lock-in, custo por mensagem
3. **Redis Streams** - Menos maduro, sem ecosystem

---

## ğŸ› ï¸ Stack TecnolÃ³gico

### ğŸ”µ Producer (Go)
| Componente | Tecnologia | VersÃ£o | Uso |
|------------|-----------|---------|-----|
| Runtime | Go | 1.21 | Linguagem principal |
| PostgreSQL Driver | pgx | v5 | ConexÃ£o com banco |
| Kafka Client | confluent-kafka-go | v2 | PublicaÃ§Ã£o de eventos |
| Patterns | Outbox Pattern | - | Garantia de entrega |

### ğŸŸ¢ Consumer (.NET)
| Componente | Tecnologia | VersÃ£o | Uso |
|------------|-----------|---------|-----|
| Runtime | .NET | 10.0 | Linguagem principal |
| Framework | Worker Service | - | Background service |
| ORM | Entity Framework Core | 8.0 | PersistÃªncia |
| CQRS | MediatR | 12.0 | Desacoplamento |
| Kafka Client | Confluent.Kafka | 2.3 | Consumo de eventos |
| Redis Client | StackExchange.Redis | 2.7 | Cache management |

### ğŸ—ï¸ Infraestrutura
| Componente | Tecnologia | VersÃ£o | Porta |
|------------|-----------|---------|-------|
| Message Broker | Apache Kafka | 7.5.0 | 9092 |
| Coordination | Zookeeper | 7.5.0 | 2181 |
| Cold Storage | PostgreSQL | 15 | 5432 |
| Fast Storage | Redis | 7 | 6379 |
| Observability | RedisInsight | latest | 8001 |
| Orchestration | Docker Compose | 2.x | - |

---

## ğŸš€ Diferenciais TÃ©cnicos

### 1. ğŸ” Transactional Outbox Pattern
Resolve o problema de escrita dual (Banco + Kafka), garantindo atomicidade e entrega no mÃ­nimo uma vez (at-least-once delivery).

### 2. ğŸ’¾ PersistÃªncia Poliglota
- **PostgreSQL:** HistÃ³rico completo, queries analÃ­ticas, ACID compliance
- **Redis:** Ãšltima posiÃ§Ã£o, acesso O(1), TTL automÃ¡tico

### 3. ğŸ›ï¸ Clean Architecture no Consumer
- SeparaÃ§Ã£o clara de responsabilidades (Domain, Application, Infrastructure)
- MediatR para desacoplamento entre camadas
- Testabilidade elevada (unit tests + integration tests)

### 4. ğŸ”„ IdempotÃªncia
Sistema preparado para mensagens duplicadas atravÃ©s de:
- Chaves Ãºnicas de identificaÃ§Ã£o (driver_id + timestamp)
- VerificaÃ§Ã£o de duplicatas antes de processar
- OperaÃ§Ãµes SET no Redis (naturalmente idempotentes)

### 5. ğŸ“¡ Event-Driven Architecture
- Desacoplamento completo entre Producer e Consumer
- Capacidade de adicionar novos consumidores sem alterar Producer
- Replay de eventos via Kafka retention (atÃ© 7 dias configurÃ¡vel)

---

## âš¡ Como Executar

### PrÃ©-requisitos
- ğŸ³ Docker 20.10+
- ğŸ™ Docker Compose 2.0+

### Executar o Sistema Completo

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/seu-usuario/kafka-go-dotnet-telemetry.git
cd kafka-go-dotnet-telemetry

# 2. Suba todos os serviÃ§os
docker-compose up -d --build

# 3. Verifique o status
docker-compose ps

# 4. Acompanhe os logs
docker-compose logs -f
```

### ServiÃ§os DisponÃ­veis

| ServiÃ§o | Porta | Acesso | Credenciais |
|---------|-------|--------|-------------|
| âš¡ Kafka | 9092 | localhost:9092 | - |
| ğŸ˜ PostgreSQL | 5432 | localhost:5432 | user_geo / password_geo |
| âš¡ Redis | 6379 | localhost:6379 | - |
| ğŸ“ˆ RedisInsight | 8001 | http://localhost:8001 | - |

---

###

## âš¡ Como Executar

### PrÃ©-requisitos
- Docker 20.10+
- Docker Compose 2.0+

### Executar o Sistema Completo

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/seu-usuario/kafka-go-dotnet-telemetry.git
cd kafka-go-dotnet-telemetry

# 2. Suba todos os serviÃ§os
docker-compose up -d --build

# 3. Verifique o status
docker-compose ps

# 4. Acompanhe os logs
docker-compose logs -f
```

### ServiÃ§os DisponÃ­veis

| ServiÃ§o | Porta | Acesso |
|---------|-------|--------|
| Kafka | 9092 | localhost:9092 |
| PostgreSQL | 5432 | localhost:5432 |
| Redis | 6379 | localhost:6379 |
| RedisInsight | 8001 | http://localhost:8001 |

---



## ğŸ§¹ Comandos Ãšteis

```bash
# Parar tudo
docker-compose down

# Parar e limpar volumes
docker-compose down -v

# Reiniciar serviÃ§o especÃ­fico
docker-compose restart consumer-dotnet

# Ver uso de recursos
docker stats

# Entrar em container
docker exec -it consumer-dotnet sh
```
